{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "covid_vaccine_data = pd.read_csv(r\"C:\\Users\\Raheyma Arshad\\Desktop\\INFO 5731 Term Project\\RQ1 - Sentiment Analysis 02\\Vaccine Tweets (With Location).csv\")\n",
    "del covid_vaccine_data['Unnamed: 0']\n",
    "covid_vaccine_data = covid_vaccine_data[covid_vaccine_data.tweet != 'tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkIt(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "    return out\n",
    "\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# Data Cleaning\n",
    "def preprocess_word(word):\n",
    "    # Remove punctuation\n",
    "    word = word.strip('\\'\"?!,.():;')\n",
    "    # Convert more than 2 letter repetitions to 2 letter\n",
    "    # funnnnny --> funny\n",
    "    word = re.sub(r'(.)\\1+', r'\\1\\1', word)\n",
    "    # Remove - & '\n",
    "    word = re.sub(r'(-|\\')', '', word)\n",
    "    # Translating the word\n",
    "    try:\n",
    "        text = TextBlob(word)\n",
    "        word = (text.translate(to ='en')).text\n",
    "    except:\n",
    "        word = word\n",
    "    return word\n",
    "\n",
    "def is_valid_word(word):\n",
    "    # Check if word begins with an alphabet\n",
    "    return (re.search(r'^[a-zA-Z][a-z0-9A-Z\\._]*$', word) is not None)\n",
    "\n",
    "def handle_emojis(tweet):\n",
    "    # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
    "    tweet = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' EMO_POS ', tweet)\n",
    "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "    tweet = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' EMO_POS ', tweet)\n",
    "    # Love -- <3, :*\n",
    "    tweet = re.sub(r'(<3|:\\*)', ' EMO_POS ', tweet)\n",
    "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "    tweet = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', tweet)\n",
    "    # Sad -- :-(, : (, :(, ):, )-:\n",
    "    tweet = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' EMO_NEG ', tweet)\n",
    "    # Cry -- :,(, :'(, :\"(\n",
    "    tweet = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', tweet)\n",
    "    return tweet\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    processed_tweet = []\n",
    "    # Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    # removing non-ascii characters i.e. characters with ascii value >= 128\n",
    "    tweet = ''.join([w if ord(w) < 128 else ' ' for w in tweet])\n",
    "    # Spelling correction\n",
    "    tweet = str(TextBlob(tweet).correct())\n",
    "    # Replaces URLs with the word URL\n",
    "    tweet = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', ' URL ', tweet)\n",
    "    # Replace @handle with the word USER_MENTION\n",
    "    tweet = re.sub(r'@[\\S]+', 'USER_MENTION', tweet)\n",
    "    # Replaces #hashtag with hashtag\n",
    "    tweet = re.sub(r'#(\\S+)', r' \\1 ', tweet)\n",
    "    # Remove RT (retweet)\n",
    "    tweet = re.sub(r'\\brt\\b', '', tweet)\n",
    "    # Replace 2+ dots with space\n",
    "    tweet = re.sub(r'\\.{2,}', ' ', tweet)\n",
    "    # Strip space, \" and ' from tweet\n",
    "    tweet = tweet.strip(' \"\\'')\n",
    "    # Replace emojis with either EMO_POS or EMO_NEG\n",
    "    tweet = handle_emojis(tweet)\n",
    "    # Replace multiple spaces with a single space\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    words = tweet.split()\n",
    "    for word in words:\n",
    "        word = preprocess_word(word)\n",
    "        if is_valid_word(word):\n",
    "            # Removing stop words\n",
    "            if word not in stop:\n",
    "                processed_tweet.append(word)\n",
    "    return ' '.join(processed_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    clean_list = []\n",
    "    #     tweet = \"Facebook Censors President @realDonaldTrump: Takes Down Fox Interview Over Comments on Children and #Coronavirus Come on over to Parler, Gab, and MeWe, Mr. President! They do not censor conservatives. #ChinaVirus #COVID19 https://t.co/iFWCO3fXFC\"\n",
    "    #filepath = r'/home/junhua/PycharmProjects/TwitterDataAnalysis/datacollection/Useful_data/useful_data.csv'\n",
    "    #dataframe = pd.read_csv(filepath)\n",
    "    #     print(dataframe.head())\n",
    "    df_list = covid_vaccine_data['tweet'].values.tolist()\n",
    "    df_sublists = chunkIt(df_list, 20)\n",
    "    for row in df_sublists[0]:\n",
    "        if not row[1]:\n",
    "            print(\"The string is empty\")\n",
    "        elif len(row[1]) < 4:\n",
    "            print(\"The string is too short\")\n",
    "        else:\n",
    "            clean_tweet = preprocess_tweet(row[1])\n",
    "            new_row = [row[0], clean_tweet, row[2], row[3], row[4]]\n",
    "            print(new_row)\n",
    "            clean_list.append(new_row)\n",
    "    new_df = pd.DataFrame(clean_list, columns=['Index', 'Tweet', 'Relationship_Date_UTC', 'Hashtags_in_Tweet', 'Location'])\n",
    "    new_df.to_csv(r'C:\\Users\\Raheyma Arshad\\Desktop\\Paper Data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
